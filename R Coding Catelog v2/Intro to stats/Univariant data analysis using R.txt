
Data Visualisation

Search this site
CONTENTS
DATA REPOSITORY
FEEDBACK
EXHIBITION 2016
Module 5: Univariate Data Visualisations

CONTENTS
1 Module 5: Univariate Data Visualisations
1.1 Learning Objectives
1.2 Visualising One Variable
1.3 Qualitative Data
1.4 Qualitative Univariate Visualisations
1.4.1 Bar Charts
1.4.2 Check Your Scales
1.4.3 Dot Plot
1.4.4 Pie Charts
1.4.5 Coxcomb Diagram (Polar Area Diagram)
1.5 Quantitative Variables
1.5.1 YouTube Data
1.5.2 Histograms
1.5.3 Boxplot
1.5.4 Density Plot
1.5.5 Overlaying Univariate Plots
1.5.6 Adding Markers and Annotations
1.5.7 Violin Plot
1.5.8 Stacked Dot Plots
1.5.9 Juxtaposing
1.6 References
Learning Objectives

The learning objectives associated with this module are: 
Differentiate between the methods used to visualise a single qualitative or quantitative variable.
Appropriately apply data visualisations commonly used for qualitative variables including bar charts and dot plots.
Understand the perceptual issues associated with the use of data visualisations based on polar coordinates including pie charts and coxcomb diagrams. 
Appropriately apply data visualisations commonly used for quantitative variables including histograms, box plots, density plots, violin plots and stacked dot plots.
Understand the issues associated with the use of histograms including small sample size and arbitrary bin width.
Use ggplot2 to create and customise common univariate data visualisations. 
Use ggplot2 to add markers, annotations, overlay and juxtapose plots. 
Critically appraise the advantages and disadvantages of common univariate visualisations and exercise judicious choice when selecting an appropriate display of the data.
Visualising One Variable

In this module we will shift our focus to developing data visualisations. We will start with the most simple case of visualising one variable. As you will discover, there is much more to simple univariate data visualisations than you would think. We will consider the numerous methods for visualising both quantitative and qualitative variables, their strengths, limitations and practical tips. We will also continue to practice ggplot2 and dig deeper into its code and features. 

Qualitative Data

For the qualitative  section of this module, we will make use of the MSNBC.com web data set available from the UCI Machine Learning Repository. You can download the msnbc.csv dataset from the data repository. This amazing dataset contains the sequence of page view categories for over 1 million unique visitors to the MSNBC.com website logged on the 28th of September, 1999. The categories, or different landing pages, included: "frontpage", "news", "tech", "local", "opinion", "on-air", "misc", "weather", "health", "living", "business", "sports", "summary", "bbs" (bulletin board service), "travel", "msn-news", and "msn-sports". The dataset may be old, but the application of web analytics is still very relevant. For example, MSNBC might want to understand how visitors are landing on their site. Are they accessing the front page, or are they using more direct links to specific content areas? A data visualisation can help answer this question very quickly and can aid MSNBC.com in understanding their website traffic. Load the msnbs.csv data into your R session and name the object msnbc.
Qualitative Univariate Visualisations

Bar Charts

Bar charts are a ubiquitous data visualisation for qualitative (nominal and ordinal) data. They use length and position to exploit our visual perception system's ability to rapidly compare different groups and categories in terms of counts/tallies, proportions and percentages, or, in other words, parts of a whole. Bar charts are a natural choice for comparing the traffic between different landing pages on the MSNBC.com website. However, before we do so, we need to a do a little bit of data wrangling in R. Bar charts are much easier to work with in ggplot2 when we summarise the data beforehand. Look at the following screen shot to preview the data structure of the msncb.csv file. 


Notice how each row represents a unique visitor and the landing pages visited. As you can see, each visitor can visit multiple landing pages. We will restrict our interest to the first page visited to get a general overview. Therefore, we are only interested in the First variable. To ensure we can use ggplot2 most effectively, we can summarise this data into a table using the awesome dplyr package (see here for a great intro). Here's the code:

> library(dplyr)
> msnbc_sum <-summarise(group_by(msnbc, First), count = n())
This code tells R to summarise the msnbc data object according to the First variable by counting the number of occurrences in the data, count = n(). The result is saved to an object called msnbc_sum. 

And here is the result:


So, there were 68,605 people that landed first on the bbs page, 17,270 people that landed first on the business page etc...

This will make the data much quicker and easier to work with. To create our bar charts, we can refer to the summarised msnbc_sum data object. We can also transform the counts to percentages and proportions by adding variables to the data object:

> msnbc_sum$Proportion <- msnbc_sum$count/nrow(msnbc)
> msnbc_sum$Percent <- msnbc_sum$count/nrow(msnbc)*100
Here is the result:



Now we are ready to construct our first bar chart.

> p1<-ggplot(msnbc_sum,aes(x = First, y = count)) 
> p1 + geom_bar(stat = "identity")


It's a start, but it isn't pretty. You should understand the stat = "identity" option we used in the code. This is a very powerful option that we need to use when we are dealing with already summarised data. ggplot2 has been built to perform statistical transformation, e.g. calculate quartiles for box plots, bins for histograms and tallies for bar charts, automatically. When we supply a data object with already pre-summarised data (e.g. msnbc_sum) we need to tell ggplot2 to skip the default transformations and base the plot on the already computed statistics. That's what we mean when we use stat = "identity".

With that out of the way, you will notice a few other issues. The categories are arranged based on alphabetical order, which makes it slow to rank the landing pages from highest to lowest. You also notice that the labels overlap on the x-axis tick labels. Let's fix up the ordering. To achieve this, we need to change the properties of the First factor. 

> msnbc_sum$First <- factor(msnbc_sum$First, levels = msnbc_sum$First[order(-msnbc_sum$count)]) 
This code reorders the levels within the First factor based on the counts. We use the - sign in front of msnbc_sum$count to indicate descending order. To check the results, re-run the bar chart.

> p1<-ggplot(msnbc_sum,aes(x = First, y = count))
> p1 + geom_bar(stat="identity")

Much better. Now the viewer can quickly assess the descending frequency of page landing sites by reading across the x-axis. We can also change count to percentage by adjusting the y aesthetic. 

> p2<-ggplot(msnbc_sum,aes(x = First, y = Percent))
> p2 + geom_bar(stat="identity")


Next, let's fix the x-axis tick mark labels and add descriptive axis labels to assist the viewer with interpreting the plot.

> p2 + geom_bar(stat="identity") + theme(axis.text.x=element_text(angle=45,hjust=1)) + 
     labs(title = "Unique Visits to Different MSNBC.com Landing Pages \n 28/09/1999",
     y = "Percentage of Unique Visitors",
     x = "Landing Page within MSNBC.com Domain")


Notice how we carefully adjusted the orientation of the x-axis tick labels using the theme() option.

We can also add useful annotations. Let's add the actual data values above the bars.

> p2 + geom_bar(stat="identity") + theme(axis.text.x=element_text(angle=45,hjust=1)) + 
     labs(title = "Unique Visits to Different MSNBC.com Landing Pages \n 28/09/1999",
     y = "Percentage of Unique Visitors",
     x = "Landing Page within MSNBC.com Domain") +
     geom_text(aes(label=round(Percent,2)), vjust = -0.5,size = 2)


We could also change the theme and colour if we needed it to follow a particular colour scheme, e.g. for a report or webpage.

> p2 + geom_bar(stat="identity",fill = "dodgerblue3" ) +  theme_minimal() + 
     theme(axis.text.x=element_text(angle=45,hjust=1)) + 
     labs(title = "Unique Visits to Different MSNBC.com Landing Pages \n 28/09/1999",
     y = "Percentage of Unique Visitors",
     x = "Landing Page within MSNBC.com Domain") +
     geom_text(aes(label=round(Percent,2)), vjust = -0.5,size = 2)
 
Check Your Scales

You can grossly misrepresent the data in bar charts by adjusting the scale. Let's zoom in on the tech, local, health, bbs, summary and sports pages, which all share a similar percentage of visitors. However, we will do something suspect with the scale. First we define a ggplot object using a filtered data object. 

> p2.2 <- ggplot(filter(msnbc_sum,First == "tech" | First == "local" | First == "health" |
     First == "bbs" | First == "summary" | First == "sports"), aes(x = First, y = Percent))
This code selects only the relevant pages.

Now we play with the y-axis scale. 

> p2.2 + geom_bar(stat = "identity") + coord_cartesian(ylim=c(5.5,6.25))


Wow! The differences appear huge. However, closer inspection of the y-axis suggests a different story. Now look what happens when we anchor the y-axis correctly at 0, which you should do if you have count/ratio data. 

> p2.2 + geom_bar(stat = "identity")
 

The difference is not so big any more. Don't deceive the viewer!

Dot Plot

Bar charts are highly accurate but can be space hungry. Let's experiment with a dot plot and the orientation of the plot to reduce the overall size, but without diminishing accuracy.

> p3 <- ggplot(msnbc_sum, aes(y = First, x = count))
> p3 + geom_point()


It doesn't look right to have the highest category at the bottom, so we can reverse the ordering.

> msnbc_sum$First <- factor(msnbc_sum$First, levels = msnbc_sum$First[order(msnbc_sum$count)])    


That looks better. Now let's add some trailing lines to help connect the dot with each y-axis tick mark label. 

> p3 <- ggplot(msnbc_sum, aes(y = First, x = count))
> p3 + geom_point() + geom_segment(aes(x = 0, y = First, xend = count,yend=First),linetype = 2)

The geom_segment() layer allows us to add lines to the plot. We use the options, x, y, xend, and yend to determine the start and finish of each line. We use the linetype = 2 to draw a dashed lined.

Finally, we can assign labels, change colour and data point values if needed.

> p3 <- ggplot(msnbc_sum, aes(y = First, x = count))
> p3 + geom_point(colour = "dodgerblue3") + 
     geom_segment(aes(x = 0, y = First, xend = count,yend=First),linetype = 2) +
     labs(title = "Unique Visits to Different MSNBC.com \n Landing Pages \n 28/09/1999",
     x = "No. of Unique Visitors",
     y = "Landing Page within MSNBC.com Domain") +
     geom_text(aes(label=round(count,2)), hjust = -.2,size = 2) +
     scale_x_continuous(limits = c(0,350000))

Notice how the scale of the x-axis and offset of the data point values had to be adjusted to fit within the plot. As you can see, the dot plot is a lot more compact, but doesn't sacrifice accuracy. The only difference between the dot plot and bar chart is the geometric object used to represent count. Switching from a greedy bar to a small point saves a lot of space.

Pie Charts

There are many perceptual challenges associated with pie charts. Comparing angles and area of segments of the pie is less accurate than comparison using bar charts and dot plots. Also, comparing the relative sizes of segments gets difficult as they do not share an aligned baseline. Pie charts are also limited in terms of the number of categories they can display. Having too many makes the visualisation cramped and difficult to discern different categories. Therefore, pie charts or any chart with polar coordinates should be used with great care. A lot of people believe they are evil and should be avoided at all cost, but I am a little more pragmatic. For some reason they are really good at grabbing attention. Maybe it's because we all love a good pie, savoury or sweet! Therefore, when accuracy isn't the main objective, you only have a few categories to represent and you supplement the chart with value labels, the infamous pie chart might still serve a purpose. Let's take a look at an example in ggplot2.

Pie charts are a little tricky in ggplot2. We need to use the coord_polar() option. Here's an example:

> p4 <- ggplot(msnbc_sum, aes(x = factor(1), y = count, fill = First))
> p4 + geom_bar(stat="identity",width = 1) + coord_polar(theta = "y")


Not a bad start, but you can see the issue of having so many categories! Some sources say no more than 12 colours should be used (Butz, 2012), while other sources advise 5 to 7 (based on short-term memory; MacDonald, 1999). Seventeen is certainly too much. 

So let's filter the data a little to consider only the top five landing pages.

> msnbc_sum_top_five <- filter(msnbc_sum, rank(count) > 12)
We also need to recalculate the proportions and percentages based on the top five plots:

> msnbc_sum_top_five$Proportion <- msnbc_sum_top_five$count/sum(msnbc_sum_top_five$count)
> msnbc_sum_top_five$Percent <- msnbc_sum_top_five$Proportion*100
Now we re-run the pie chart using the top five filtered data set.

> p5 <- ggplot(msnbc_sum_top_five, aes(x = factor(1), y = count, fill = First))
> p5 + geom_bar(stat="identity",width = 1) + coord_polar(theta = "y")


This is much easier to associate the colour with the categories. Let's clean up the plot a little to make it look more like a classic pie chart and add some data value labels to overcome some of the perceptual issues with comparing angles and area. (Note the interesting code required to properly align the text labels!).

p5 + geom_bar(stat="identity",width = 1) + coord_polar(theta = "y") +
  theme(axis.ticks=element_blank(),
        axis.title=element_blank(),
        axis.text.y=element_blank(),
        axis.text.x=element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank()) +
  labs(fill = "Top Five Landing Pages") +
  geom_text(aes(y = (cumsum(count)-count)+(count/2),
                label=round(Percent,2)))


Coxcomb Diagram (Polar Area Diagram)

Coxcomb diagrams or polar area diagrams, which are believed to have been first introduced by Florence Nightingale, are similar to pie charts, but use area instead of angles for comparisons. Each category or segment of the diagram has an equal angle, but the area or the extending length of the segments vary.

> p6 <- ggplot(msnbc_sum_top_five, aes(x = First,y=count,fill=First))
> p6 + geom_bar(stat="identity",width = 1) + coord_polar()


According to Cleveland and McGill (1985), the angle and area represented using pie charts should be more accurate than area alone. Therefore, pie charts, if you have to use them, might be the better choice.

These are some interesting examples of polar coordinate systems, but always remember, use pie charts and other variations with caution. They do sacrifice a lot of accuracy.

Quantitative Variables

YouTube Data

In this section, we will cover methods for visualising univariate quantitative variables (interval and ratio). We will use the Youtube.csv data which was also taken from the UCI Machine Learning Repository. A .csv version of the dataset is available from the Data Repository. The dataset contains the video characteristics of over 24,000 YouTube clips. Suppose we want to visualise the distribution of YouTube video duration. Understanding the distribution of quantitative variables can help us to understand the spread of the data, describe its distribution to others, identify appropriate descriptive methods, check for the presence of outliers, and test assumptions about the underlying population distribution. Visualising the distribution of a quantitative variable is an important first step in exploratory data analysis.

Histograms

Let's start with a basic histogram. Histograms order and count quantitative variables into equal interval ranges, called bins. The relative height of bars are used to represent the frequency of data points that fit within each bin. Histograms are a useful and quick way to explore the distribution of a quantitative variable. However, they do have a number of limitations. Histograms are not suited to small samples and the bin width or number of bins used to create a histogram can have a major impact on the appearance of the distribution. Check out my Shiny Histogram app to see what I mean (If it doesn't appear, make sure your browser isn't blocking it). 

EXPLORING HISTOGRAMS

Let's make a start:

> p6 <- ggplot(Youtube, aes(x = duration))
> p6 + geom_histogram()


As the number of bins is set arbitrarily at 30, let's try adjusting the number of bins to see if we can improve the histogram.

> p6 + geom_histogram(bins=100)

That didn't do much! 

Boxplot

There might be some outliers that are creating an issue with the scale. Let's check using a box plot:

> p7 <- ggplot(Youtube, aes(x = factor(1), y = duration))
> p7 + geom_boxplot(width = .25)


As suspected, there are heaps of outliers. You cannot discern the box plot!

Let's clean the data by removing the outliers. We will filter-out the cases that are considered to be extreme outliers according to the following rules:

Extreme lower outlier < Q1 - IQR*3
Extreme upper outlier > Q3 + IQR*3
where Q1 and Q3 refer to the 1st and 3rd quartiles of the data and IQR is the inter-quartile range.

> Youtube_clean<-filter(Youtube, duration < (quantile(Youtube$duration,.75) + 
  IQR(Youtube$duration)*3)))
Now we re-run the box plot.

> p8 <- ggplot(Youtube_clean, aes(x = factor(1), y = duration)) 
> p8 + geom_boxplot(width = .25)


Looking good. Now for the histogram:

> p9<- ggplot(Youtube_clean, aes(x = duration))
> p9 + geom_histogram()


Much better. The scale has been fixed and we can start to get a much better picture of the nature of the distribution. We can add some colour and experiment with the number of bins. We have a lot of data, so the histogram should be able to support many bins.

> p9 + geom_histogram(colour = "white", bins = 100)


How would you describe the shape of this distribution? Check the following diagram.

DISTRIBUTION SHAPES

Density Plot

We can also plot a density estimate when our sample sizes are large.

> p9 + geom_density(fill = "grey")


The density estimate is based on the generic kernal density function from the base stats package. Kernal density estimation uses a nonparametric smoothing algorithm to estimate the underlying population probability density function.  Be wary. These visualisations are also susceptible to greater sampling variability in small samples. 

Overlaying Univariate Plots

Let's overlay the histogram and density plot to see how they compare.

> p9 + geom_density(fill = "grey") + 
     geom_histogram(colour="white",aes(duration,..density..),
     alpha = 1/2,bins=100)


To ensure the histogram and density plot share the same scale, we use the ..density.. aesthetic option in geom_histogram(). We also use the alpha option to make the histogram transparent. As you can see, the density estimate smooths out the minor peaks and troughs that are apparent in the histogram. We can add some additional transparency and colour to help differentiate the two plot types. 

> p9 + geom_density(fill = "dodgerblue", alpha = 1/2) + 
     geom_histogram(colour="white",aes(duration,..density..),
     alpha = 1/2,bins = 100)

Adding Markers and Annotations

You can add markers and annotations for the mean and median using geom_vline() and annotate():

> p9 <- p9 + geom_density(fill = "dodgerblue", alpha = 1/2) + 
     geom_histogram(colour="white",aes(duration,..density..), 
     alpha = 1/2,bins = 100) + 
     geom_vline(xintercept= median(Youtube_clean$duration)) + 
     annotate("text",label = "Median",x = 190, y = 0.006) + 
     geom_vline(xintercept= mean(Youtube_clean$duration),linetype=2) + 
     annotate("text",label = "Mean",x = 240, y = 0.004)
> p9


You will need to play around with the placement of the annotations. This plot shows a clear positively skewed distribution. The tail of the distribution pulls the mean duration to the right of the median. 
Violin Plot

Violin plots are similar to a box plot, but convey the density estimate instead of quartiles.

> p10 <- ggplot(Youtube_clean,aes(x=factor(1),y = duration))
> p10 + geom_violin(width = .25,fill="grey")


Be wary. Each side of the violin plot is a mirror image. It does not represent an additional variable. 
If we overlap a box plot, you can see how each offer a different perspective to the data.

> p10 <- ggplot(Youtube_clean,aes(x=factor(1),y = duration)) 
> p10 + geom_violin(width = .10, fill="grey") + geom_boxplot(width = .25, fill = "white")


Box plots and violin plots are great for comparing the distribution of a quantitative variable across many groups as we will see in the following module. Histograms and density plots are far more effective when considering a univariate distribution. 

Stacked Dot Plots

We have already taken a look at one type of dot plot used to summarise and compare the frequency of categories for a qualitative variable. Dot plots are also used to summarise the distribution of a quantitative variable. The dots, which usually represent a data value, are stacked on top of each other based on pre-defined bins. They appear to be a very detailed histogram. For small samples, as you will see, they are ideal because the sample can be counted. However, for large datasets, you should opt for histograms and density plots. Let' s consider an example using the YouTube data. 

> p11 <- ggplot(Youtube_clean,aes(x = duration))
> p11 + geom_dotplot()


That doesn't look right! Let's try adjusting the bins.

> p11 <- ggplot(Youtube_clean,aes(x = duration))
> p11 + geom_dotplot(binwidth = 10)


That's a bit better, but it's clear the sample size is too large to support the use of a dot plot. You couldn't count all the dots even if we increased the bin width. 

However, if the sample was smaller, dot plots are a great choice. Let's take a random sample of n = 50 and plot the sample's distribution of duration.

> set.seed(462243) #Set the random seed to replicate the plot below
> p11 <- ggplot(sample_n(Youtube_clean,50),aes(x = duration))
> p11 + geom_dotplot()


Now that looks much better. Notice how the dots represent individual values, so the viewer has a sense of sample size. 
Juxtaposing

Juxtaposing is the method of aligning multiple plots together in order to facilitate comparison. In later modules we will explore this in greater depth when we take a closer look at the method of faceting. For now, we will focus on a simple example. As we have discovered, different data visualisations can portray different features of the data. Sometimes it is helpful to look at multiple representations of the same data. When we do this, it's important to align the visualisations to facilitate comparison and ensure the relationship between the visualisations' data are maintained. 

The following example shows you how to use the cowplot package to align multiple ggplots together. The complete code is shown as it is important to assign all the layers to the plotting object before calling the plot_grid() function from the cowplot package. The exercise will juxtapose the boxplot from p8 and the histogram and density plot from p9. 

First we ensure the plotting layers are all assigned correctly to the p8 and p9 ggplot objects. 

> p8 <- ggplot(Youtube_clean, aes(x = factor(1), y = duration)) + 
     geom_boxplot(width = .50) + scale_y_continuous(limits = c(0, 800))

> p9 <- ggplot(Youtube_clean, aes(x = duration)) +
     geom_density(fill = "dodgerblue", alpha = 1/2) + 
     geom_histogram(colour="white",aes(duration,..density..),
     alpha = 1/2,bins = 100) +
     geom_vline(xintercept= median(Youtube_clean$duration)) + 
     annotate("text",label = "Median",x = 180, y = 0.006) + 
     geom_vline(xintercept= mean(Youtube_clean$duration),linetype=2) +
     annotate("text",label = "Mean",x = 240, y = 0.004) +
     scale_x_continuous(limits = c(0, 800))
Notice how we set the scale limits to scale_x_continuous(limits = c(0, 800)) for the density plot and and scale_y_continuous(limits = c(0, 800)) for the box plot. This ensures the plots are perfectly aligned by sharing a common scale. Next we install (if required) and load cowplot. 

> install.packages("cowplot") 
> library(cowplot)
Cowplot changes the default grey theme. If you want to retain the grey theme in your plots then place the following code before you use the plot_grid function.

> theme_set(theme_gray())
Now we juxtapose the plots:

> plot_grid(p9, p8 + coord_flip(), ncol=1,align="v",
     rel_heights = c(2,1))



We had to flip the box plot to run horizontally using coord_flip(). We also set a number of layout parameters to juxtapose correctly. ncol sets the number of columns to use in the grid, align sets the alignment and rel_heights sets the relative heights of each plot. In the code above, we set p9 to be twice the size of p8, the box plot. 

The labels could do with some cleaning, but overall, this is a nice example of juxtaposing visualisations of the same data. Sometimes this can lead to surprising findings and also a greater understanding behind the nature of different methods. 

References

MacDonald, L. W. (1999). Using color effectively in computer graphics. IEEE Computer Graphics and Applications, 19(4), 20–35. doi:10.1109/38.773961. Retrieved from http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773961
Buts, A. (2012). 2. Visual Perception: Optimizing Information Visualization regarding the human visual system. Retrieved February 1, 2016, from https://www.medien.ifi.lmu.de/lehre/ws1112/iv/folien/IV-W11-02-Perception.pdf 
Return to top

Recent Site Activity|Report Abuse|Print Page|Remove Access|Powered By Google Sites