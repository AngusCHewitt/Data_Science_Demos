memoryResults <- profmem(UCS_Satellite_Database <- read.delim("../UCS_Satellite_Database", stringsAsFactors = FALSE))
head(memoryResults) # display operations and memory used
head(memoryResults) # display operations and memory used
head(memoryResults) # display operations and memory used
# This is memory allocated for operations - not memory finally used...
sum(memoryResults$bytes) # 12368375 bytes
# ...which is approx 3x the size of the final object...
object.size(UCS_Satellite_Database) # 3322752 bytes
# tracemem ----------------------------------------------------------------
# alert when objects are copied
# is this enabled?
capabilities()["profmem"]
# demonstrate that nothing happens
UCS_Satellite_Database$newColumn <- runif(nrow(UCS_Satellite_Database))
tracemem(UCS_Satellite_Database) # turn on tracing
# now an alert is issued
UCS_Satellite_Database$newColumn <- runif(nrow(UCS_Satellite_Database))
untracemem(UCS_Satellite_Database) # turn off alert
tracingState() # is tracing on?
untracemem(UCS_Satellite_Database) # turn off alert
# now an alert is issued
UCS_Satellite_Database$newColumn <- runif(nrow(UCS_Satellite_Database))
memoryResults <- profmem(UCS_Satellite_Database <- read.delim("../UCS_Satellite_Database", stringsAsFactors = FALSE))
head(memoryResults) # display operations and memory used
# This is memory allocated for operations - not memory finally used...
sum(memoryResults$bytes) # about 12368375 bytes
# ...which is approx 3x the size of the final object...
object.size(UCS_Satellite_Database) # about 3322752 bytes
# tracemem ----------------------------------------------------------------
# alert when objects are copied
# is this enabled in your build of R?
capabilities()["profmem"]
# demonstrate that nothing happens
UCS_Satellite_Database$newColumn <- runif(nrow(UCS_Satellite_Database))
tracemem(UCS_Satellite_Database) # turn on tracing
# now an alert is issued
UCS_Satellite_Database$newColumn <- runif(nrow(UCS_Satellite_Database))
untracemem(UCS_Satellite_Database) # turn off alert
tracingState() # is tracing on?
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
aDataFrame <- data.frame(apogee = as.numeric(UCS_Satellite_Database$Apogee..km.),
perigee = as.numeric(UCS_Satellite_Database$Perigee..km.),
orbit = UCS_Satellite_Database$Class.of.Orbit)
object.size(aDataFrame) # ~39352 bytes. Varies by system
tracemem(aDataFrame)
anotherDataFrame <-
data.frame(
apogee = runif(1, min = 300, max = 900),
perigee = runif(1, min = 187, max = 900),
orbit = sample(c("LEO", "GEO", "MEO"), 1)
)
aDataFrame <- rbind(aDataFrame, anotherDataFrame)
untracemem(aDataFrame)
install.packages("data.table")
library(data.table)
aDataTable <- data.table(apogee = as.numeric(UCS_Satellite_Database$Apogee..km.),
perigee = as.numeric(UCS_Satellite_Database$Perigee..km.),
orbit = UCS_Satellite_Database$Class.of.Orbit)
tracemem(aDataTable)
object.size(aDataTable) # ~39,912 bytes
# add data to an existing row in aDataFrame
aDataTable[ 1, c("apogee", "perigee", "orbit")] <-
data.table(apogee = runif(1, min = 300, max = 900),
perigee = runif(1, min = 187, max = 900),
orbit = sample(c("LEO", "GEO", "MEO"), 1)
)
object.size(aDataTable) # ~39,352 bytes
untracemem(aDataFrame)
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
aDataFrame <- data.frame(apogee = as.numeric(UCS_Satellite_Database$Apogee..km.),
perigee = as.numeric(UCS_Satellite_Database$Perigee..km.),
orbit = UCS_Satellite_Database$Class.of.Orbit)
object.size(aDataFrame) # ~39,352 bytes. Varies by system
tracemem(aDataFrame)
anotherDataFrame <-
data.frame(
apogee = runif(1, min = 300, max = 900),
perigee = runif(1, min = 187, max = 900),
orbit = sample(c("LEO", "GEO", "MEO"), 1)
)
aDataFrame <- rbind(aDataFrame, anotherDataFrame)
untracemem(aDataFrame)
aDataTable <- data.table(apogee = as.numeric(UCS_Satellite_Database$Apogee..km.),
perigee = as.numeric(UCS_Satellite_Database$Perigee..km.),
orbit = UCS_Satellite_Database$Class.of.Orbit)
tracemem(aDataTable)
object.size(aDataTable) # ~39,912 bytes
# add data to an existing row in aDataFrame
aDataTable[ 1, c("apogee", "perigee", "orbit")] <-
data.table(apogee = runif(1, min = 300, max = 900),
perigee = runif(1, min = 187, max = 900),
orbit = sample(c("LEO", "GEO", "MEO"), 1)
)
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
# a function to return the expected end of life of a satellite
ExpectedEOLSatellite <- function(ucsSatObs) {
dangerRatio <- switch(
as.character(ucsSatObs[8]),
elliptical = .1,
GEO = .25,
LEO = .5,
MEO = .75,
... = 1
)
expectedLife <- ifelse(is.na(ucsSatObs[20]), 15, as.integer(ucsSatObs[20]))
adjustedLife <- as.integer(expectedLife * 365 * dangerRatio)
EOLdate <- as.Date(ucsSatObs[[19]], "%m/%d/%Y") + adjustedLife
return(EOLdate)
}
UCS_Satellite_Database$ExpectEOL <- apply(UCS_Satellite_Database, 1, ExpectedEOLSatellite)
library(parallel)
detectCores() # identifies number of available cores
myCluster <- makeCluster(detectCores())
parApply(cl = myCluster, UCS_Satellite_Database, 1, ExpectedEOLSatellite)
# install.packages("microbenchmark)
library(microbenchmark)
#
install.packages("microbenchmark)
library(microbenchmark)
benchmarkresults <- microbenchmark(
original = apply(UCS_Satellite_Database, 1, ExpectedEOLSatellite),
parallel = parApply(cl = myCluster, UCS_Satellite_Database, 1, ExpectedEOLSatellite)
)
boxplot(benchmarkresults) # it takes LONGER to parallel process
#
install.packages("microbenchmark")
install.packages("microbenchmark")
library(microbenchmark)
benchmarkresults <- microbenchmark(
original = apply(UCS_Satellite_Database, 1, ExpectedEOLSatellite),
parallel = parApply(cl = myCluster, UCS_Satellite_Database, 1, ExpectedEOLSatellite)
)
boxplot(benchmarkresults) # it takes LONGER to parallel process
detectCores() # identifies number of available cores
myCluster <- makeCluster(detectCores())
benchmarkresults <- microbenchmark(
original = apply(UCS_Satellite_Database, 1, ExpectedEOLSatellite),
parallel = parApply(cl = myCluster, UCS_Satellite_Database, 1, ExpectedEOLSatellite)
)
boxplot(benchmarkresults) # it takes LONGER to parallel process
# SQLite support
# install.packages("RSQLite")
library(DBI)
# SQLite support
install.packages("RSQLite")
warnings()
# SQLite support
# install.packages("RSQLite")
library(DBI)
SQLiteIsHere <- "05_02_associatedFiles/ucs_satellite.db" # could also be ":memory:"
mySQLiteDB <- dbConnect(RSQLite::SQLite(),SQLiteIsHere)
setwd("~/Desktop/Exercise Files/Chapter 05")
mySQLiteDB <- dbConnect(RSQLite::SQLite(),SQLiteIsHere)
# add extended math functions
RSQLite::initExtension(mySQLiteDB)
# access from data.frame
randomMedianDF <- function() {
median(sample(UCS_Satellite_Database$Launch.Mass..kg.., size = 100), na.rm = TRUE)
}
# access from file on disk
library(readr)
# access from file on disk
install.packages("readr")
# access from file on disk
# install.packages("readr")
library(readr)
randomMedianFile <- function() {
SatDat <- read_tsv("../UCS_Satellite_Database", )
median(sample(SatDat$`Launch Mass (kg.)`, size = 100), na.rm = TRUE)
}
# access from database
randomMedianSQL <- function() {
do_this_sqlite <- "
SELECT `Launch Mass (kg.)`
FROM satellites
WHERE `Launch Mass (kg.)` != ''
ORDER BY RANDOM()
LIMIT 100
"
returnDF <- dbGetQuery(mySQLiteDB,do_this_sqlite)
return(median(returnDF$`Launch Mass (kg.)`))
}
# profvis shows memory use. 16x for file over SQL
# reason - all SQL processing done outside of R.
# results saved as profvis-DFvsFilevsSQL.Rprofvis
library(profvis)
# profvis shows memory use. 16x for file over SQL
# reason - all SQL processing done outside of R.
# results saved as profvis-DFvsFilevsSQL.Rprofvis
install.packages("profvis")
# profvis shows memory use. 16x for file over SQL
# reason - all SQL processing done outside of R.
# results saved as profvis-DFvsFilevsSQL.Rprofvis
# install.packages("profvis")
library(profvis)
profvis({
randomMedianDF()
randomMedianFile()
randomMedianSQL()
})
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
profvis({
randomMedianDF()
randomMedianFile()
randomMedianSQL()
})
# microbenchmark shows cpu use. file > SQL
# install.packages("microbenchmark")
library(microbenchmark)
benchmarkresults <- microbenchmark(
DataFrame = randomMedianDF(),
File = randomMedianFile(),
SQL = randomMedianSQL()
)
boxplot(benchmarkresults)
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
# access from a data.frame -------------------------------------------------------
randomMedianDF <- function() {
median(sample(UCS_Satellite_Database$Launch.Mass..kg.., size = 100), na.rm = TRUE)
}
# access from file on disk ------------------------------------------------
# install.packages("readr")
library(readr)
randomMedianFile <- function() {
SatDat <- read_tsv("../UCS_Satellite_Database" )
median(sample(SatDat$`Launch Mass (kg.)`, size = 100), na.rm = TRUE)
}
# install.packages("RSQLite")
library(DBI)
SQLiteIsHere <- "05_02_associatedFiles/ucs_satellite.db" # is your working directory "Chapter 05" ?
mySQLiteDB <- dbConnect(RSQLite::SQLite(),SQLiteIsHere)
# add extended math functions
RSQLite::initExtension(mySQLiteDB)
randomMedianSQL <- function() {
do_this_sqlite <- "
SELECT `Launch Mass (kg.)`
FROM satellites
WHERE `Launch Mass (kg.)` != ''
ORDER BY RANDOM()
LIMIT 100
"
returnDF <- dbGetQuery(mySQLiteDB,do_this_sqlite)
return(median(returnDF$`Launch Mass (kg.)`))
}
# install.packages("profvis")
library(profvis)
profvis({
randomMedianDF()
randomMedianFile()
randomMedianSQL()
})
# install.packages("microbenchmark")
library(microbenchmark)
benchmarkresults <- microbenchmark(
DataFrame = randomMedianDF(),
File = randomMedianFile(),
SQL = randomMedianSQL()
)
boxplot(benchmarkresults)
profvis({
randomMedianDF()
randomMedianFile()
randomMedianSQL()
})
profvis({
randomMedianDF()
randomMedianFile()
randomMedianSQL()
})
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
# spark.rstudio.com
install.packages("httpuv")
install.packages("sparklyr")
library(sparklyr)
spark_install(version = "2.1.0")
devtools::install_github("rstudio/sparklyr")
install.packages("devtools")
library(devtools)
devtools::install_github("rstudio/sparklyr")
# connect to a local version of Spark
library(sparklyr)
sc <- spark_connect(master = "local")
# open the Spark UI. Connections tab, Spark UI, opens browser
spark_web(sc)
# open the Spark UI. Connections tab, Spark UI, opens browser
spark_web(sc)
# load data into the spark cluster
library(dplyr)
ucsSat_tbl <- copy_to(sc, UCS_Satellite_Database, "spark_ucs")
# if you receive MalformedInputException, check encoding of source data
src_tbls(sc) # shows tables in spark
# use dplyr (tidyverse) to manipulate Spark
ucsSat_tbl %>% filter(Class_of_Orbit == "LEO")
View(ucsSat_tbl)
# or use SQL
library(DBI)
dbGetQuery(sc, "SELECT `Class_of_ORBIT` FROM spark_ucs LIMIT 5")
# import
UCS_Satellite_Database <-
read.delim("../UCS_Satellite_Database",
stringsAsFactors = FALSE,
fileEncoding = "latin1")
# clean
UCS_Satellite_Database$Launch.Mass..kg.. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Launch.Mass..kg..))
UCS_Satellite_Database$Power..watts. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Power..watts.))
UCS_Satellite_Database$Apogee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Apogee..km.))
UCS_Satellite_Database$Perigee..km. <-
as.numeric(gsub(",", "", UCS_Satellite_Database$Perigee..km.))
UCS_Satellite_Database$Class.of.Orbit <-
as.factor(trimws(UCS_Satellite_Database$Class.of.Orbit))
# spark.rstudio.com
install.packages("httpuv", "sparklyr")
install.packages("httpuv", "sparklyr")
install.packages("httpuv")
install.packages("httpuv")
install.packages("sparklyr")
install.packages("sparklyr")
# install.packages("httpuv")
# install.packages("sparklyr")
library(sparklyr)
install.packages("httpuv")
install.packages("httpuv")
install.packages("sparklyr")
library(sparklyr)
install.packages("httpuv")
install.packages("httpuv")
install.packages("sparklyr")
library(sparklyr)
##-- create table of all variable coefficient levels
library(tidyverse) # tidy Data
library(data.table) # Big Data
library(fitzRoy) # AFL functions
library(lme4) # mixed mods
load("/Users/angushewitt/Desktop/AFL Datasets/Model Data/Step_11_Pred_Model_Dataset.Rdata") ##-- each player last recorded game
load("/Users/angushewitt/Desktop/AFL Datasets/Misc/rubik_Cube_dt.Rdata") ##-- rubix cube var coefs
source(file = "/Users/angushewitt/Desktop/AFL test case/Weekly Data Refresh Workflows/Features building & Preds dts/Load GameDay Mixed Models.R") # load gameday models using source
##-- last ganme was from 2019
AFL_Actuals_Features_2020 %>%
as.data.table() -> AFL_Actuals_Features_2020$Seasons
rubik_Cube_dt %>%
as.data.table() -> rubik_Cube_dt
max(AFL_Actuals_Features_2020$Date)
# "2020-10-24"
##-- create table of all variable coefficient levels
library(tidyverse) # tidy Data
library(data.table) # Big Data
library(fitzRoy) # AFL functions
library(lme4) # mixed mods
load("/Users/angushewitt/Desktop/AFL Datasets/Model Data/Step_11_Pred_Model_Dataset.Rdata") ##-- each player last recorded game
load("/Users/angushewitt/Desktop/AFL Datasets/Misc/rubik_Cube_dt.Rdata") ##-- rubix cube var coefs
source(file = "/Users/angushewitt/Desktop/AFL test case/Weekly Data Refresh Workflows/Features building & Preds dts/Load GameDay Mixed Models.R") # load gameday models using source
##-- last ganme was from 2019
AFL_Actuals_Features_2020 %>%
as.data.table() -> AFL_Actuals_Features_2020$Seasons
rubik_Cube_dt %>%
as.data.table() -> rubik_Cube_dt
max(AFL_Actuals_Features_2020$Date)
# "2020-10-24"
##--  in the prediction mod dt only keep var that want be manipulated in the scenario mods
AFL_Actuals_Features_2020 %>%
dplyr::filter(GameDay_Role == "Key_Forward") %>%
select(ID, Date, Season, lagged_no_Games_pl_Categories, first_Game_season_Factor, yr_int, yr_intervals_2020,
Goal_scoring_Fatasy_scores_centre , Goal_scoring_Fatasy_scores_pos_sd  , Goal_scoring_Fatasy_scores_neg_sd ,
Contested.Possessions_minus_CM_centre , Contested.Possessions_minus_CM_pos_sd  , Contested.Possessions_minus_CM_neg_sd ,
Mid_stats_centre , Mid_stats_pos_sd  , Mid_stats_neg_sd ,
Hit.Outs_centre , Hit.Outs_pos_sd  , Hit.Outs_neg_sd ) %>%
mutate(Obs = 1) -> AFL_Actuals_Features_2020_Key_Frwd
##-- right join pred mod dt  to rubix cude vau the obs =1 (all players will get all possible comob for particular GD role)
rubik_Cube_dt %>%
dplyr::filter(GameDay_Role == "Key_Forward") %>%
mutate(Obs = 1) -> rubik_Cube_dt_Key_Frwd
##-- right join pred mod dt  to rubix cude vau the obs =1 (all players will get all possible comob for particular GD role)
rubik_Cube_dt_Key_Frwd %>%
right_join(AFL_Actuals_Features_2020_Key_Frwd, by = "Obs") %>%
select(-Obs) -> rubik_Cube_dt_Key_Frwd
##-- add prediction and odds HGS in next game
rubik_Cube_dt_Key_Frwd %>%
ungroup() %>%
mutate(HGS_Probability = if_else(first_Game_season_Factor == "No", predict(Key_Forward_Mod, newdata = rubik_Cube_dt_Key_Frwd, type =  "response"),
predict(Key_Forward_Mod_1st_Game_season, newdata = rubik_Cube_dt_Key_Frwd, type =  "response"))) %>%
mutate(HGS_Odds = if_else(1/HGS_Probability < 10, round(1/HGS_Probability, 2), round(1/HGS_Probability))) %>%
mutate(HGS_Probability = round(HGS_Probability * 100),5) %>%
mutate(HGS_Odds = if_else(HGS_Odds > 10000, 10000, HGS_Odds)) %>%
select(ID, Season, Date, Career_Positions_Meaningful_GD_Roles, GD_Height_Categories, TOG_Categories, Cnt_Favs_Team_Level, Cnt_Favs_Opp_Level, Cnt_Elite_Great_Key_Defs_Opp_Level,
HGS_Probability, HGS_Odds) %>%
dplyr::filter(Season >= 2019) -> rubik_Cube_dt_Key_Frwd
rm(list = ls())  # caution: delete all objects in .GlobalEnv
gc()  # free system memory
