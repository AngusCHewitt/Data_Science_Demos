18/09/06 16:25:59 INFO SparkContext: Running Spark version 2.1.0
18/09/06 16:25:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/06 16:25:59 INFO SecurityManager: Changing view acls to: markniemann-ross
18/09/06 16:25:59 INFO SecurityManager: Changing modify acls to: markniemann-ross
18/09/06 16:25:59 INFO SecurityManager: Changing view acls groups to: 
18/09/06 16:25:59 INFO SecurityManager: Changing modify acls groups to: 
18/09/06 16:25:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(markniemann-ross); groups with view permissions: Set(); users  with modify permissions: Set(markniemann-ross); groups with modify permissions: Set()
18/09/06 16:25:59 INFO Utils: Successfully started service 'sparkDriver' on port 49965.
18/09/06 16:25:59 INFO SparkEnv: Registering MapOutputTracker
18/09/06 16:25:59 INFO SparkEnv: Registering BlockManagerMaster
18/09/06 16:25:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/06 16:25:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/09/06 16:25:59 INFO DiskBlockManager: Created local directory at /private/var/folders/j3/b3qbl4ps6h5c11b7clk37t8r0000gr/T/blockmgr-a325afa7-8312-4588-8a41-d738dd8d35f1
18/09/06 16:25:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/09/06 16:25:59 INFO SparkEnv: Registering OutputCommitCoordinator
18/09/06 16:26:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/09/06 16:26:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/09/06 16:26:00 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49965/jars/sparklyr-2.1-2.11.jar with timestamp 1536276360102
18/09/06 16:26:00 INFO Executor: Starting executor ID driver on host localhost
18/09/06 16:26:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49966.
18/09/06 16:26:00 INFO NettyBlockTransferService: Server created on 127.0.0.1:49966
18/09/06 16:26:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/06 16:26:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49966, None)
18/09/06 16:26:00 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49966 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49966, None)
18/09/06 16:26:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49966, None)
18/09/06 16:26:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49966, None)
18/09/06 16:26:00 INFO SharedState: Warehouse path is 'file:/Users/markniemann-ross/Desktop/Exercise%20Files/Chapter%2005/spark-warehouse'.
18/09/06 16:26:00 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/09/06 16:26:01 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/09/06 16:26:05 INFO ObjectStore: ObjectStore, initialize called
18/09/06 16:26:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/09/06 16:26:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/09/06 16:26:06 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/09/06 16:26:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/09/06 16:26:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/09/06 16:26:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/09/06 16:26:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/09/06 16:26:08 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/09/06 16:26:08 INFO ObjectStore: Initialized ObjectStore
18/09/06 16:26:08 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/09/06 16:26:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/09/06 16:26:08 INFO HiveMetaStore: Added admin role in metastore
18/09/06 16:26:08 INFO HiveMetaStore: Added public role in metastore
18/09/06 16:26:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/09/06 16:26:09 INFO HiveMetaStore: 0: get_all_databases
18/09/06 16:26:09 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_all_databases	
18/09/06 16:26:09 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/09/06 16:26:09 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/09/06 16:26:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/09/06 16:26:09 INFO SessionState: Created local directory: /var/folders/j3/b3qbl4ps6h5c11b7clk37t8r0000gr/T/a89f9c4b-cc6b-4b1c-bd0b-219a74ea5d3e_resources
18/09/06 16:26:09 INFO SessionState: Created HDFS directory: /tmp/hive/markniemann-ross/a89f9c4b-cc6b-4b1c-bd0b-219a74ea5d3e
18/09/06 16:26:09 INFO SessionState: Created local directory: /var/folders/j3/b3qbl4ps6h5c11b7clk37t8r0000gr/T/markniemann-ross/a89f9c4b-cc6b-4b1c-bd0b-219a74ea5d3e
18/09/06 16:26:09 INFO SessionState: Created HDFS directory: /tmp/hive/markniemann-ross/a89f9c4b-cc6b-4b1c-bd0b-219a74ea5d3e/_tmp_space.db
18/09/06 16:26:09 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/markniemann-ross/Desktop/Exercise%20Files/Chapter%2005/spark-warehouse
18/09/06 16:26:09 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:26:09 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:26:09 INFO HiveMetaStore: 0: get_database: global_temp
18/09/06 16:26:09 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/09/06 16:26:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/09/06 16:26:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/09/06 16:26:11 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:26:11 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:26:11 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:26:11 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:26:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/09/06 16:26:11 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/09/06 16:27:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/09/06 16:27:36 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:36 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:36 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:36 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/09/06 16:27:36 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/09/06 16:27:37 INFO CodeGenerator: Code generated in 252.506095 ms
18/09/06 16:27:37 INFO SparkContext: Starting job: collect at utils.scala:44
18/09/06 16:27:37 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
18/09/06 16:27:37 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
18/09/06 16:27:37 INFO DAGScheduler: Parents of final stage: List()
18/09/06 16:27:37 INFO DAGScheduler: Missing parents: List()
18/09/06 16:27:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:41), which has no missing parents
18/09/06 16:27:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/09/06 16:27:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/09/06 16:27:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49966 (size: 4.6 KB, free: 366.3 MB)
18/09/06 16:27:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:41)
18/09/06 16:27:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/09/06 16:27:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/09/06 16:27:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/09/06 16:27:37 INFO Executor: Fetching spark://127.0.0.1:49965/jars/sparklyr-2.1-2.11.jar with timestamp 1536276360102
18/09/06 16:27:37 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49965 after 12 ms (0 ms spent in bootstraps)
18/09/06 16:27:37 INFO Utils: Fetching spark://127.0.0.1:49965/jars/sparklyr-2.1-2.11.jar to /private/var/folders/j3/b3qbl4ps6h5c11b7clk37t8r0000gr/T/spark-2fe2ca07-0e6b-4228-b78b-ee1ba08ead68/userFiles-d44d900e-8862-4e81-a361-619aeea0084a/fetchFileTemp4608662049093687190.tmp
18/09/06 16:27:37 INFO Executor: Adding file:/private/var/folders/j3/b3qbl4ps6h5c11b7clk37t8r0000gr/T/spark-2fe2ca07-0e6b-4228-b78b-ee1ba08ead68/userFiles-d44d900e-8862-4e81-a361-619aeea0084a/sparklyr-2.1-2.11.jar to class loader
18/09/06 16:27:37 INFO CodeGenerator: Code generated in 15.122305 ms
18/09/06 16:27:37 INFO CodeGenerator: Code generated in 11.83498 ms
18/09/06 16:27:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
18/09/06 16:27:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 238 ms on localhost (executor driver) (1/1)
18/09/06 16:27:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/09/06 16:27:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.253 s
18/09/06 16:27:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.411049 s
18/09/06 16:27:38 INFO SparkSqlParser: Parsing command: spark_ucs
18/09/06 16:27:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `spark_ucs`
18/09/06 16:27:38 INFO SparkSqlParser: Parsing command: `spark_ucs`
18/09/06 16:27:38 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/09/06 16:27:38 INFO CodeGenerator: Code generated in 19.019434 ms
18/09/06 16:27:38 INFO CodeGenerator: Code generated in 12.679355 ms
18/09/06 16:27:38 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
18/09/06 16:27:38 INFO DAGScheduler: Registering RDD 15 (sql at NativeMethodAccessorImpl.java:0)
18/09/06 16:27:38 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
18/09/06 16:27:38 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
18/09/06 16:27:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/09/06 16:27:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/09/06 16:27:38 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/09/06 16:27:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 232.0 KB, free 366.1 MB)
18/09/06 16:27:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 56.3 KB, free 366.0 MB)
18/09/06 16:27:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49966 (size: 56.3 KB, free: 366.2 MB)
18/09/06 16:27:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
18/09/06 16:27:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/09/06 16:27:39 WARN TaskSetManager: Stage 1 contains a task of very large size (2111 KB). The maximum recommended task size is 100 KB.
18/09/06 16:27:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 2162186 bytes)
18/09/06 16:27:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/09/06 16:27:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49966 in memory (size: 4.6 KB, free: 366.2 MB)
18/09/06 16:27:39 INFO CodeGenerator: Code generated in 203.428684 ms
18/09/06 16:27:40 INFO CodeGenerator: Code generated in 618.614313 ms
18/09/06 16:27:40 INFO ContextCleaner: Cleaned accumulator 1
18/09/06 16:27:40 INFO ContextCleaner: Cleaned accumulator 0
18/09/06 16:27:40 INFO ContextCleaner: Cleaned accumulator 52
18/09/06 16:27:42 INFO MemoryStore: Block rdd_12_0 stored as values in memory (estimated size 2.2 MB, free 363.8 MB)
18/09/06 16:27:42 INFO BlockManagerInfo: Added rdd_12_0 in memory on 127.0.0.1:49966 (size: 2.2 MB, free: 364.1 MB)
18/09/06 16:27:42 INFO CodeGenerator: Code generated in 5.759891 ms
18/09/06 16:27:42 INFO CodeGenerator: Code generated in 13.784123 ms
18/09/06 16:27:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2820 bytes result sent to driver
18/09/06 16:27:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3476 ms on localhost (executor driver) (1/1)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/09/06 16:27:42 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 3.478 s
18/09/06 16:27:42 INFO DAGScheduler: looking for newly runnable stages
18/09/06 16:27:42 INFO DAGScheduler: running: Set()
18/09/06 16:27:42 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/09/06 16:27:42 INFO DAGScheduler: failed: Set()
18/09/06 16:27:42 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 363.8 MB)
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.8 MB)
18/09/06 16:27:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49966 (size: 3.7 KB, free: 364.1 MB)
18/09/06 16:27:42 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/09/06 16:27:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
18/09/06 16:27:42 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/09/06 16:27:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/09/06 16:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/09/06 16:27:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
18/09/06 16:27:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on localhost (executor driver) (1/1)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/09/06 16:27:42 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.033 s
18/09/06 16:27:42 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 3.566644 s
18/09/06 16:27:42 INFO CodeGenerator: Code generated in 5.439227 ms
18/09/06 16:27:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `spark_ucs`
18/09/06 16:27:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49966 in memory (size: 3.7 KB, free: 364.1 MB)
18/09/06 16:27:42 INFO SparkContext: Starting job: collect at utils.scala:197
18/09/06 16:27:42 INFO DAGScheduler: Registering RDD 22 (collect at utils.scala:197)
18/09/06 16:27:42 INFO DAGScheduler: Got job 2 (collect at utils.scala:197) with 1 output partitions
18/09/06 16:27:42 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:197)
18/09/06 16:27:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/09/06 16:27:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/09/06 16:27:42 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:197), which has no missing parents
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 232.0 KB, free 363.6 MB)
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 56.3 KB, free 363.6 MB)
18/09/06 16:27:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49966 (size: 56.3 KB, free: 364.0 MB)
18/09/06 16:27:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at utils.scala:197)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/09/06 16:27:42 WARN TaskSetManager: Stage 3 contains a task of very large size (2111 KB). The maximum recommended task size is 100 KB.
18/09/06 16:27:42 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 2162178 bytes)
18/09/06 16:27:42 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/09/06 16:27:42 INFO BlockManager: Found block rdd_12_0 locally
18/09/06 16:27:42 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
18/09/06 16:27:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 36 ms on localhost (executor driver) (1/1)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/09/06 16:27:42 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:197) finished in 0.036 s
18/09/06 16:27:42 INFO DAGScheduler: looking for newly runnable stages
18/09/06 16:27:42 INFO DAGScheduler: running: Set()
18/09/06 16:27:42 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/09/06 16:27:42 INFO DAGScheduler: failed: Set()
18/09/06 16:27:42 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:197), which has no missing parents
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 363.6 MB)
18/09/06 16:27:42 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 363.6 MB)
18/09/06 16:27:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49966 (size: 3.7 KB, free: 364.0 MB)
18/09/06 16:27:42 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at collect at utils.scala:197)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/09/06 16:27:42 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
18/09/06 16:27:42 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/09/06 16:27:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/09/06 16:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/09/06 16:27:42 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
18/09/06 16:27:42 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
18/09/06 16:27:42 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/09/06 16:27:42 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:197) finished in 0.006 s
18/09/06 16:27:42 INFO DAGScheduler: Job 2 finished: collect at utils.scala:197, took 0.068399 s
18/09/06 16:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_ucs` AS `zzz1`
WHERE (0 = 1)
18/09/06 16:27:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/09/06 16:27:43 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:43 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:43 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:43 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/09/06 16:27:43 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/09/06 16:27:43 INFO CodeGenerator: Code generated in 7.716829 ms
18/09/06 16:27:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/09/06 16:27:54 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:54 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:54 INFO HiveMetaStore: 0: get_database: default
18/09/06 16:27:54 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_database: default	
18/09/06 16:27:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/09/06 16:27:54 INFO audit: ugi=markniemann-ross	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/09/06 16:27:54 INFO SparkContext: Starting job: collect at utils.scala:44
18/09/06 16:27:54 INFO DAGScheduler: Got job 3 (collect at utils.scala:44) with 1 output partitions
18/09/06 16:27:54 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:44)
18/09/06 16:27:54 INFO DAGScheduler: Parents of final stage: List()
18/09/06 16:27:54 INFO DAGScheduler: Missing parents: List()
18/09/06 16:27:54 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
18/09/06 16:27:54 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 363.5 MB)
18/09/06 16:27:54 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 363.5 MB)
18/09/06 16:27:54 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49966 (size: 4.6 KB, free: 364.0 MB)
18/09/06 16:27:54 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
18/09/06 16:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[32] at map at utils.scala:41)
18/09/06 16:27:54 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/09/06 16:27:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6358 bytes)
18/09/06 16:27:54 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/09/06 16:27:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1243 bytes result sent to driver
18/09/06 16:27:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
18/09/06 16:27:54 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/09/06 16:27:54 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:44) finished in 0.008 s
18/09/06 16:27:54 INFO DAGScheduler: Job 3 finished: collect at utils.scala:44, took 0.014573 s
18/09/06 16:28:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_ucs`
WHERE (`Class_of_Orbit` = "LEO")
18/09/06 16:28:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_ucs`
WHERE (`Class_of_Orbit` = "LEO")
18/09/06 16:28:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `spark_ucs`
WHERE (`Class_of_Orbit` = "LEO")
LIMIT 10
18/09/06 16:28:33 INFO InMemoryTableScanExec: Predicate isnotnull(Class_of_Orbit#282) generates partition filter: ((Class_of_Orbit.count#6709 - Class_of_Orbit.nullCount#6708) > 0)
18/09/06 16:28:33 INFO InMemoryTableScanExec: Predicate (Class_of_Orbit#282 = LEO) generates partition filter: ((Class_of_Orbit.lowerBound#6707 <= LEO) && (LEO <= Class_of_Orbit.upperBound#6706))
18/09/06 16:28:33 INFO SparkContext: Starting job: collect at utils.scala:197
18/09/06 16:28:33 INFO DAGScheduler: Got job 4 (collect at utils.scala:197) with 1 output partitions
18/09/06 16:28:33 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:197)
18/09/06 16:28:33 INFO DAGScheduler: Parents of final stage: List()
18/09/06 16:28:33 INFO DAGScheduler: Missing parents: List()
18/09/06 16:28:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[35] at collect at utils.scala:197), which has no missing parents
18/09/06 16:28:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 229.2 KB, free 363.3 MB)
18/09/06 16:28:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 54.9 KB, free 363.3 MB)
18/09/06 16:28:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49966 (size: 54.9 KB, free: 364.0 MB)
18/09/06 16:28:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/09/06 16:28:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[35] at collect at utils.scala:197)
18/09/06 16:28:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/09/06 16:28:33 WARN TaskSetManager: Stage 6 contains a task of very large size (2111 KB). The maximum recommended task size is 100 KB.
18/09/06 16:28:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 2162104 bytes)
18/09/06 16:28:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/09/06 16:28:33 INFO BlockManager: Found block rdd_12_0 locally
18/09/06 16:28:33 INFO CodeGenerator: Code generated in 6.419943 ms
18/09/06 16:28:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49966 in memory (size: 4.6 KB, free: 364.0 MB)
18/09/06 16:28:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49966 in memory (size: 3.7 KB, free: 364.0 MB)
18/09/06 16:28:33 INFO ContextCleaner: Cleaned accumulator 270
18/09/06 16:28:33 INFO ContextCleaner: Cleaned accumulator 271
18/09/06 16:28:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49966 in memory (size: 56.3 KB, free: 364.0 MB)
18/09/06 16:28:33 INFO ContextCleaner: Cleaned accumulator 161
18/09/06 16:28:33 INFO CodeGenerator: Code generated in 64.404898 ms
18/09/06 16:28:33 INFO CodeGenerator: Code generated in 3.874415 ms
18/09/06 16:28:33 WARN Executor: 1 block locks were not released by TID = 6:
[rdd_12_0]
18/09/06 16:28:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 4703 bytes result sent to driver
18/09/06 16:28:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 154 ms on localhost (executor driver) (1/1)
18/09/06 16:28:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/09/06 16:28:33 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:197) finished in 0.154 s
18/09/06 16:28:33 INFO DAGScheduler: Job 4 finished: collect at utils.scala:197, took 0.174799 s
18/09/06 16:28:33 INFO CodeGenerator: Code generated in 48.329699 ms
18/09/06 16:29:33 INFO SparkSqlParser: Parsing command: SELECT `Class_of_ORBIT` FROM spark_ucs LIMIT 5
18/09/06 16:29:33 INFO SparkContext: Starting job: collect at utils.scala:197
18/09/06 16:29:33 INFO DAGScheduler: Got job 5 (collect at utils.scala:197) with 1 output partitions
18/09/06 16:29:33 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:197)
18/09/06 16:29:33 INFO DAGScheduler: Parents of final stage: List()
18/09/06 16:29:33 INFO DAGScheduler: Missing parents: List()
18/09/06 16:29:33 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[37] at collect at utils.scala:197), which has no missing parents
18/09/06 16:29:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 227.7 KB, free 363.3 MB)
18/09/06 16:29:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 54.1 KB, free 363.3 MB)
18/09/06 16:29:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49966 (size: 54.1 KB, free: 364.0 MB)
18/09/06 16:29:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
18/09/06 16:29:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at collect at utils.scala:197)
18/09/06 16:29:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/09/06 16:29:33 WARN TaskSetManager: Stage 7 contains a task of very large size (2111 KB). The maximum recommended task size is 100 KB.
18/09/06 16:29:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 2162104 bytes)
18/09/06 16:29:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/09/06 16:29:33 INFO BlockManager: Found block rdd_12_0 locally
18/09/06 16:29:33 INFO CodeGenerator: Code generated in 8.22596 ms
18/09/06 16:29:33 WARN Executor: 1 block locks were not released by TID = 7:
[rdd_12_0]
18/09/06 16:29:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1495 bytes result sent to driver
18/09/06 16:29:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 39 ms on localhost (executor driver) (1/1)
18/09/06 16:29:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/09/06 16:29:33 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:197) finished in 0.039 s
18/09/06 16:29:33 INFO DAGScheduler: Job 5 finished: collect at utils.scala:197, took 0.051400 s
18/09/06 16:29:33 INFO CodeGenerator: Code generated in 4.005685 ms
18/09/06 16:56:00 INFO ContextCleaner: Cleaned shuffle 0
18/09/06 16:56:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49966 in memory (size: 54.9 KB, free: 364.0 MB)
18/09/06 16:56:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:49966 in memory (size: 54.1 KB, free: 364.1 MB)
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 64
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 63
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 62
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 61
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 60
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 59
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 58
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 57
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 56
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 55
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 54
18/09/06 16:56:00 INFO ContextCleaner: Cleaned accumulator 53
18/09/06 16:56:00 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:49966 in memory (size: 56.3 KB, free: 364.1 MB)
