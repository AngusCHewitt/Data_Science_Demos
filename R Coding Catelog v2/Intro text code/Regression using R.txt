To perform a linear regression in R you must create a new object so that you can use the linear regression
output.

Examass.lm<-lm(Examination.Mark~Assignment.Mark,Examass.data)

The command summary.lm will provide details of the analysis output

summary.lm(Examass.lm)

You can also use the abline command to add the regression line to your scatterplot

plot(Examass.data,type="p",xlab="your x axis label here",ylab="your y axis

label here",main="your graph title")

abline(Examass.lm)

To calculate the confidence intervals, use the confint command

confint(Examass.lm,level=0.95)

#using the simple lm further proves not only correl.test and analysis of var. but also a series of error plots. 
> plot(lm(My_Super.lm))




Two-Way Tables. Done with table, or in the R Commander by following Statistics . Contingency
Tables . Two-way Tables. You can also enter and analyze a two-way table.

table
prop.table
addmargins
rowPercents (Rcmdr)

colPercents (Rcmdr)
totPercents(Rcmdr)
A <- xtabs(~ gender + race, data = RcmdrTestDrive)
xtabs( Freq ~ Class + Sex, data = Titanic) # from built in table
barplot(A, legend.text=TRUE)
barplot(t(A), legend.text=TRUE)
barplot(A, legend.text=TRUE, beside = TRUE)

#Spine plot: plots categorical versus categorical
>spineplot(gender ~ race, data = RcmdrTestDrive)

Scatterplot: look for linear association and correlation.

carb ~ optden, data = Formaldehyde (boring)
conc ~ rate, data = Puromycin
xyplot(accel ~ dist, data = attenu) nonlinear association
xyplot(eruptions ~ waiting, data = faithful) (linear, two groups)
xyplot(Petal.Width ~ Petal.Length, data = iris)
xyplot(pressure ~ temperature, data = pressure) (exponential growth)
xyplot(weight ~ height, data = women) (strong positive linear)

#correlations test of sig with paired x,y var. - test is for + cor, both and - t distn, preason's stat
> with(Highway1, cor.test(rate, sigs1, alternative="greater", 
+   method="pearson"))

> with(Highway1, cor.test(rate, sigs1, alternative="two.sided", 
+   method="pearson"))

> with(Highway1, cor.test(rate, sigs1, alternative="less", method="pearson"))

#procedure of stardising var for residual analysis for homogenality
> mysuper <- local({
+   .Z <- scale(mysuper[,c("Res","Trend")])
+   within(mysuper, {
+     Z.Trend <- .Z[,2]
+     Z.Res <- .Z[,1] 
+   })
+ })

#normality tests; Y - My_Super and X  - ASX300, first plot examine if The presence of a non-linear relationship exists.
the variance of the residuals appears to increase with predicted value (if so a transformation may be needed), test for hetero
finally test by EDA and static procedures that the random error is ND. 
> hmod <- lm(Y ~ X, data = XY)
> layout(matrix(1:2, ncol = 2))+
+ plot(Y ~ X, data = XY)+
+ abline(hmod)+
+ plot(hmod, which = 1)

#X/Y scatterplot - see have the options of various lines and c.i. tools
> scatterplot(My_Super~ASX300_Accum, reg.line=FALSE, smooth=FALSE, 
+   spread=FALSE, id.method='mahal', id.n = 2, boxplots=FALSE, span=0.5, 
+   xlab="ASX300_Accum", ylab="My_Super", main="My_Super vs ASX300_Accum", 
+   data=My_Super)

# add the line of best fit (least square method (Im)
> scatterplot(My_Super~ASX300_Accum, reg.line=lm, smooth=FALSE, spread=FALSE, 
+   id.method='mahal', id.n = 2, boxplots=FALSE, span=0.5, xlab="ASX300_Accum", 
+   ylab="My_Super", main="My_Super vs ASX300_Accum", data=My_Super)
 